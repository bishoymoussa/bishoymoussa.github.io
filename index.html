<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="author" content="Bishoy M. Galoaa">
<title>Bishoy Galoaa</title>
<!-- Google tag (gtag.js) --> 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4E8G468480"></script> 
<script> 
window.dataLayer = window.dataLayer || []; 
function gtag(){dataLayer.push(arguments);} 
gtag('js', new Date()); 
gtag('config', 'G-4E8G468480'); 
</script>
<style>
/* Minimalist style for Bishoy Galoaa's academic site */
body {
    font-family: 'Georgia', serif;
    color: #1a1a1a;
    background-color: #fefefe;
    line-height: 1.6;
    margin: 0;
    padding: 0;
}

main {
    max-width: 700px;
    margin: 0 auto;
    padding: 2rem 1.5rem;
}

.hero {
    text-align: center;
    margin-bottom: 2rem;
}

.profile {
    width: 140px;
    height: 140px;
    object-fit: cover;
    border-radius: 50%;
    border: 2px solid #ccc;
    margin-bottom: 1rem;
}

h1 {
    font-size: 2rem;
    margin-bottom: 0.3rem;
}

.tagline {
    font-style: italic;
    color: #444;
}

.social-links {
    margin: 1rem 0;
}

.social-links a {
    margin: 0 0.3rem;
}

.quote {
    font-size: 1.1rem;
    margin: 2rem 0;
    padding-left: 1rem;
    border-left: 3px solid #ccc;
    color: #333;
    font-family: 'Palatino Linotype', serif;
}

.quote span {
    display: block;
    font-size: 0.9rem;
    color: #666;
    margin-top: 0.5rem;
}

section {
    margin-bottom: 2rem;
}

.section-header {
    cursor: pointer;
    display: flex;
    justify-content: space-between;
    align-items: center;
    border-bottom: 1px solid #ddd;
    padding-bottom: 0.3rem;
    margin-bottom: 1rem;
}

h2 {
    font-size: 1.3rem;
    color: #222;
    margin: 0;
}

.toggle-icon {
    font-size: 1.2rem;
    transition: transform 0.3s ease;
}

.collapsed .toggle-icon {
    transform: rotate(-90deg);
}

.section-content {
    transition: max-height 0.5s ease, opacity 0.3s ease;
    max-height: 1000px;
    opacity: 1;
    overflow: hidden;
}

.collapsed .section-content {
    max-height: 0;
    opacity: 0;
    margin-top: 0;
    margin-bottom: 0;
}

ul {
    list-style: disc;
    padding-left: 1.5rem;
    overflow-wrap: break-word;
    word-wrap: break-word;
}

li {
    margin-bottom: 0.7rem;
    max-width: 100%;
    box-sizing: border-box;
    word-wrap: break-word;
    overflow-wrap: break-word;
    hyphens: auto;
}

.section-content {
    word-wrap: break-word;
    overflow-wrap: break-word;
    max-width: 100%;
    box-sizing: border-box;
}

a {
    color: #0056b3;
    text-decoration: none;
}

a:hover {
    text-decoration: underline;
}

.links ul {
    list-style: none;
    padding-left: 0;
}

.links li {
    margin-bottom: 0.5rem;
}

footer {
    text-align: center;
    font-size: 0.8rem;
    color: #666;
    margin-top: 3rem;
    padding-top: 1rem;
    border-top: 1px solid #eee;
}

/* Enhanced interactive dropdown styles */
.dropdown {
    position: relative;
    display: inline-block;
    color: #0056b3;
    border-bottom: 1px dotted #0056b3;
    cursor: pointer;
}

.dropdown-text {
    display: inline-block;
    color: inherit;
}

.dropdown-content {
    visibility: hidden;
    position: absolute;
    background-color: white;
    min-width: 180px;
    box-shadow: 0px 4px 12px rgba(0,0,0,0.15);
    border-radius: 6px;
    padding: 0;
    z-index: 1;
    opacity: 0;
    transform: translateY(10px);
    transition: opacity 0.3s, transform 0.3s;
    left: 50%;
    margin-left: -90px; /* Half of the min-width */
    top: 100%;
    margin-top: 8px;
    overflow: hidden;
}

.dropdown-content:before {
    content: '';
    position: absolute;
    top: -8px;
    left: 50%;
    margin-left: -8px;
    width: 0;
    height: 0;
    border-left: 8px solid transparent;
    border-right: 8px solid transparent;
    border-bottom: 8px solid white;
}

.dropdown-content.active {
    visibility: visible;
    opacity: 1;
    transform: translateY(0);
}

.dropdown-content a {
    color: #0056b3;
    padding: 12px 16px;
    text-decoration: none;
    display: block;
    text-align: left;
    border-bottom: 1px solid #f2f2f2;
    transition: background-color 0.2s;
}

.dropdown-content a:last-child {
    border-bottom: none;
}

.dropdown-content a:hover {
    background-color: #f5f8fa;
    text-decoration: none;
}

.dropdown-content a i {
    margin-right: 8px;
    opacity: 0.7;
}

.insight-box {
    background: #f9f9f9;
    border-left: 3px solid #888;
    padding: 1rem 1.2rem;
    margin: 1.2rem 0;
    border-radius: 0 6px 6px 0;
}
.insight-box p { margin: 0 0 0.6rem 0; font-size: 0.95rem; color: #333; }
.insight-box p:last-child { margin-bottom: 0; }
.video-wrap {
    position: relative;
    padding-bottom: 56.25%;
    height: 0;
    overflow: hidden;
    margin: 1rem auto 0.5rem auto;
    border-radius: 6px;
    border: 1px solid #ddd;
    max-width: 560px;
}
.video-wrap video {
    position: absolute;
    top: 0; left: 0;
    width: 100%; height: 100%;
    border: 0;
}
.video-caption {
    font-size: 0.82rem;
    color: #555;
    font-style: italic;
    text-align: center;
    margin-top: 0.3rem;
}

.badge {
    display: inline-block;
    font-size: 0.7rem;
    font-family: 'Georgia', serif;
    padding: 1px 6px;
    border-radius: 3px;
    margin-left: 6px;
    vertical-align: middle;
}
.badge-oral { background: #e8f4e8; color: #2a6e2a; border: 1px solid #b0d8b0; }
.badge-spotlight { background: #fff4e0; color: #7a4f00; border: 1px solid #f5d080; }
.badge-nominee { background: #f0eaff; color: #4a2a8a; border: 1px solid #c5aff0; }
.badge-preprint { background: #f5f5f5; color: #555; border: 1px solid #ccc; }
.badge-new { background: #fdecea; color: #8a1a0a; border: 1px solid #f5b0a0; }
</style>
</head>
<body>
<main>
    <section class="hero">
        <img src="resources/1727639612700.jpeg" alt="Bishoy Galoaa" class="profile">
        <h1>Bishoy M. Galoaa</h1>
        <p class="tagline">PhD Student • Machine Learning Researcher • Engineer</p>
        <div class="social-links">
            <a href="https://www.linkedin.com/in/bishoy-galoaa-153668149/" target="_blank">LinkedIn</a> |
            <a href="https://github.com/bishoymoussa" target="_blank">GitHub</a> |
            <a href="https://scholar.google.com/citations?user=tuwQ2GgAAAAJ&hl=en" target="_blank">Google Scholar</a> |
            <a href="mailto:galoaa.b@northeastern.edu">galoaa.b@northeastern.edu</a>
        </div>
    </section>
    
    <blockquote class="quote">
        "The real question is not whether machines think but whether men do. The mystery which surrounds a thinking machine already surrounds a thinking man."<br>
        <span>– B.F. Skinner</span>
    </blockquote>
    
    <section>
        <div class="section-header" onclick="toggleSection(this.parentNode)">
            <h2>About Me</h2>
            <span class="toggle-icon">↓</span>
        </div>
        <div class="section-content">
            <p>I'm an upcoming PhD student in the Electrical and Computer Engineering department at Northeastern University's College of Engineering. I work under the supervision of <a href="https://coe.northeastern.edu/people/ostadabbas-sarah/" target="_blank">Prof. Sarah Ostadabbas</a> in the <a href="https://ostadabbas.sites.northeastern.edu/" target="_blank">Augmented Cognition Lab (ACLab)</a>. My research centers on <strong>motion-centric video understanding and reasoning</strong> — building systems that don't merely extrapolate visual patterns, but <em>deduce</em> causal structure from observed motion. I'm particularly interested in how vision-language models can move beyond statistical pattern completion toward genuine physical and spatial reasoning. This connects to broader work in multi-object tracking, human-machine interaction, and medical AI.</p>
        </div>
    </section>
    
    <section>
        <div class="section-header" onclick="toggleSection(this.parentNode)">
            <h2>Motion-Centric Reasoning &amp; Vision-Language Models</h2>
            <span class="toggle-icon">↓</span>
        </div>
        <div class="section-content">
            <p>A core challenge I'm pursuing: most current VLMs act as <em>stochastic extrapolators</em>. Trained on massive visual corpora, they bias toward the statistically probable — a pendulum seen swinging to Point B is predicted to return to Point A, because that completes a symmetric arc. But this ignores the physics: initial conditions, energy dissipation, non-conservative forces. The model pattern-matches; it doesn't <em>reason</em>.</p>

            <div class="insight-box">
                <p><strong>The Extrapolator vs. The Visual Observer</strong></p>
                <p><strong>Extrapolator (current VLMs):</strong> sees the arc → assumes a periodic function → predicts completion. Prioritizes visual symmetry over physical constraints.</p>
                <p><strong>Visual Observer (the goal):</strong> observes initial state, recognizes constraints (fixed pivot, gravity, friction), accounts for hidden dissipative variables → deduces that the return height must be h<sub>final</sub> &lt; h<sub>initial</sub>.</p>
                <p>Walter Lewin famously put his nose — and his life — on the line to demonstrate this principle:</p>
                <div class="video-wrap">
                    <video controls autoplay width="560" height="315">
                        <source src="resources/motion_demo.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <p class="video-caption">Prof. Walter Lewin releases a 15 kg pendulum from his chin. He trusts physics — a true push would smash his face. Energy is conserved, not extrapolated.</p>
                <p style="margin-top:0.8rem; font-size:0.9rem;">My work on motion-centric systems aims to bridge this gap: from pattern completion to causal deduction.</p>
            </div>

            <ul>
                <li><strong>Motion-Centric Video Understanding:</strong> Query-free motion discovery and description systems that autonomously identify and describe events in videos, and text-to-motion generation (Lang2Motion) enabling natural language control of motion synthesis.</li>
                <li><strong>Multi-Object Tracking:</strong> Transformer-enhanced and graph-based algorithms for tracking in complex environments — including occlusions, crowded scenes, and multi-camera setups.</li>
                <li><strong>Spatial Reasoning in VLMs:</strong> Learning structured spatial and counting reasoning from pedagogically-organized video content.</li>
                <li><strong>Human-Machine Interaction:</strong> Motion analysis and uncertainty-aware anomaly detection for exoskeleton control and rehabilitation.</li>
                <li><strong>Medical AI:</strong> Personalized prognostic models for oncology via interpretable machine learning.</li>
            </ul>
        </div>
    </section>
    
    <section>
        <div class="section-header" onclick="toggleSection(this.parentNode)">
            <h2>Publications</h2>
            <span class="toggle-icon">↓</span>
        </div>
        <div class="section-content" style="display: block; max-height: none; opacity: 1;">
            <p style="font-weight:bold; color:#222; margin-bottom:0.5rem;">2026</p>
            <ul>
                <li>
                    <strong>MoReGen: Multi-Agent Motion-Reasoning Engine for Code-based Text-to-Video Synthesis</strong><br>
                    X. Bai, H. Liang, <em>B. Galoaa</em>, et al. — CVPR 2026
                    <span class="badge badge-new">New</span>
                </li>
                <li>
                    <strong>UniTrack: Differentiable Graph Representation Learning for Multi-Object Tracking</strong><br>
                    <em>B. Galoaa</em>, X. Bai, U. Nandi, S. Amraee, S. Ostadabbas — ICLR 2026
                    <span class="badge badge-spotlight">Nectar Track · Spotlight Oral · 3DV 2026</span>
                </li>
                <li>
                    <strong>K-Track: Kalman-Enhanced Tracking for Accelerating Deep Point Trackers on Edge Devices</strong><br>
                    <em>B. Galoaa</em>, P. Closas, S. Ostadabbas — WACVW 2026
                </li>
                <li>
                    <strong>LAPA: Look Around and Pay Attention — Multi-camera Point Tracking Reimagined with Transformers</strong><br>
                    <em>B. Galoaa</em>, X. Bai, S. Moezzi, et al. — 3DV 2026
                    <span class="badge badge-oral">Oral</span>
                    <span class="badge badge-nominee">Best Paper Nominee</span>
                </li>
            </ul>

            <p style="font-weight:bold; color:#222; margin-bottom:0.5rem; margin-top:1rem;">2025</p>
            <ul>
                <li><strong>SPARTAN: Spatiotemporal Pose-Aware Retrieval for Text-Guided Autonomous Navigation</strong><br>
                    X. Bai, S. A. Sreeramagiri, <em>B. Galoaa</em>, et al. — BMVC 2025</li>
                <li><strong>More Than Meets the Eye: Enhancing Multi-Object Tracking with Softmax Splatting and Optical Flow</strong><br>
                    <em>B. Galoaa</em>, S. Amraee, S. Ostadabbas — ICML 2025</li>
                <li><strong>Dragontrack: Transformer-Enhanced Graphical Multi-Person Tracking</strong><br>
                    <em>B. Galoaa</em>, S. Amraee, S. Ostadabbas — WACV 2025</li>
                <li><strong>Classification of Infant Sleep–Wake States from Natural Overnight In-Crib Videos</strong><br>
                    S. Moezzi, M. Wan, <em>B. Galoaa</em>, et al. — WACVW 2025</li>
                <li><strong>Advancing Prognostics in Oncology: ML Models for Predicting Survival in Undifferentiated Pleomorphic Sarcoma</strong><br>
                    A. G. Girgis, <em>B. M. Galoaa</em>, et al. — Annals of Surgical Oncology, 2025</li>
                <li><strong>Predicting Long-Term Survival in Myxofibrosarcoma</strong><br>
                    S. Rampam, A. G. Girgis, <em>B. M. Galoaa</em>, et al. — Surgical Oncology, 2025</li>
                <li><strong>Extraskeletal Osteosarcoma: MicroRNA Patterns</strong><br>
                    S. A. Lozano-Calderon, <em>B. M. Galoaa</em>, et al. — CTOS 2025</li>
                <li><strong>Real-Time Uncertainty Detection for Safe, Adaptive Exoskeleton Control</strong><br>
                    <em>B. Galoaa</em> et al. — ICRA Workshops 2025</li>
            </ul>

            <p style="font-weight:bold; color:#222; margin-bottom:0.5rem; margin-top:1rem;">2024</p>
            <ul>
                <li><strong>Multiple Toddler Tracking in Indoor Videos</strong><br>
                    S. Amraee, <em>B. Galoaa</em>, et al. — WACVW 2024</li>
                <li><strong>A Personalized Predictive Model for Salivary Gland Cancer</strong><br>
                    A. Girgis, <em>B. Galoaa</em>, A. Devaiah — COSM 2024</li>
                <li><strong>A Novel AI Model for Optimizing Treatment of Salivary Gland Malignancies</strong><br>
                    A. Girgis, <em>B. Galoaa</em>, A. Devaiah — AAO-HNSF 2024</li>
                <li><strong>Bias or Best Fit? SEER vs. NCDB in ML for Osteosarcoma Survival</strong><br>
                    A. G. Girgis, <em>B. M. Galoaa</em>, et al. — Clinical Orthopaedics and Related Research, 2024</li>
                <li><strong>Machine Learning–Assisted Decision Making in Orthopaedic Oncology</strong><br>
                    P. A. Rizk, M. R. Gonzalez, <em>B. M. Galoaa</em>, et al. — accepted for publication</li>
            </ul>

            <p style="font-weight:bold; color:#222; margin-bottom:0.5rem; margin-top:1rem;">Preprints &amp; Under Review</p>
            <ul>
                <li><strong>Structured Over Scale: Learning Spatial Reasoning from Educational Video</strong><br>
                    B. Galoaa, X. Bai, and S. Ostadabbas — under review, 2026
                    <span class="badge badge-preprint">Preprint</span></li>
                <li><strong>Track and Caption Any Motion: Query-Free Motion Discovery and Description in Videos</strong><br>
                    B. Galoaa and S. Ostadabbas — under review, 2026
                    <span class="badge badge-preprint">Preprint</span></li>
                <li><strong>Lang2Motion: Bridging Language and Motion Through Joint Embedding Spaces</strong><br>
                    B. Galoaa, X. Bai, and S. Ostadabbas — under review, 2026
                    <span class="badge badge-preprint">Preprint</span></li>
                <li><strong>Uncertainty-Aware Ankle Exoskeleton Control</strong><br>
                    F. M. Tourk, B. Galoaa, S. Shajan, A. J. Young, M. Everett, and M. K. Shepherd — arXiv preprint arXiv:2508.21221, 2025
                    <span class="badge badge-preprint">arXiv</span></li>
                <li><strong>Cognitive Learning through Hierarchical Prototypes and Dynamic Focus</strong><br>
                    <em>B. Galoaa</em>, S. Ostadabbas — under review, 2025
                    <span class="badge badge-preprint">Preprint</span></li>
                <li><strong>ML Algorithms for Survival Prediction in Synovial Sarcoma</strong><br>
                    J. O. Werenski, S. Rampam, <em>B. Galoaa</em>, et al. — under review
                    <span class="badge badge-preprint">Preprint</span></li>
            </ul>
        </div>
    </section>

    <section>
        <div class="section-header" onclick="toggleSection(this.parentNode)">
            <h2>30-Day Novel Ideas Challenge</h2>
            <span class="toggle-icon">↓</span>
        </div>
        <div class="section-content">
            <p>This section highlights a creative experiment where I aimed to build one novel idea per day over a month.</p>
    
            <!-- Progress bar -->
            <div style="margin: 1rem 0;">
                <label for="progress" style="display: block; font-weight: bold; margin-bottom: 0.3rem;">Progress: 5 / 30 ideas</label>
                <div style="background-color: #e0e0e0; border-radius: 8px; height: 20px; width: 100%;">
                    <div style="width: 16.66%; background-color: #636363; height: 100%; border-radius: 8px;"></div>
                </div>
            </div>
    
            <ul>
                <li><a href="https://github.com/bishoymoussa/inattention-notabene" target="_blank">Inattention NotaBene</a> – A novel regularization method that strategically "forgets" less important features through a stacked dropout mechanism, offering an alternative to traditional attention mechanisms.</li>
                <li><a href="https://github.com/bishoymoussa/ROCKET" target="_blank">ROCKET</a> – An innovative path planning system that identifies collision paths first to find optimal trajectories in complex environments using inverse collision sampling.</li>
                <li><a href="https://github.com/bishoymoussa/secretary-template-matching" target="_blank">Secretary Template Matching</a> – An online template matching algorithm inspired by the Secretary Problem, dynamically adjusting thresholds based on observed data patterns for improved real-time decision-making.</li>
                <li><a href="https://github.com/bishoymoussa/2F1B" target="_blank">2F1B</a> – A novel optimization technique introducing controlled oscillation in neural network training by alternating two forward steps with one backward step, enhancing the optimization trajectory.</li>
                <li><a href="https://github.com/bishoymoussa/knock-knock" target="_blank">Knock-Knock</a> – An optimization algorithm inspired by bat echolocation, emitting "echo signals" to navigate complex loss landscapes effectively.</li>
            </ul>
            <p>Originally shared as a public challenge on <a href="https://www.linkedin.com/in/bishoy-galoaa-153668149/" target="_blank">LinkedIn</a>.</p>
        </div>
    </section>
    
    <section>
        <div class="section-header" onclick="toggleSection(this.parentNode)">
            <h2>Awards</h2>
            <span class="toggle-icon">↓</span>
        </div>
        <div class="section-content">
            <ul>
                <li><strong>Best Paper Award Nominee</strong> — International Conference on 3D Vision (3DV 2026)
                    <span class="badge badge-nominee">Nominee</span><br>
                    <span style="font-size:0.88rem; color:#555;">For "Look Around and Pay Attention: Multi-camera Point Tracking Reimagined with Transformers"</span></li>
                <li><strong>Best Poster Presentation Award</strong> — COSM-AHNSF (Spring 2025)</li>
                <li><strong>COE Outstanding Graduate Student Award</strong> — Northeastern University (2025)</li>
                <li><strong>COE Outstanding Graduate Student Award</strong> — Northeastern University (2024)</li>
                <li><strong>Best of Scientific Orals</strong> — AAO-HNSF Annual Meeting &amp; OTO EXPO (2024)</li>
            </ul>
        </div>
    </section>
    
    <section class="links">
        <div class="section-header" onclick="toggleSection(this.parentNode)">
            <h2>More</h2>
            <span class="toggle-icon">↓</span>
        </div>
        <div class="section-content">
            <ul>
                <li><a href="resources/CV_Bishoy_Galoaa_2025.pdf">Download CV</a></li>
                <!-- <li><a href="https://www.mgbmskoncology.org/" target="_blank">MGB MSK Oncology Tool</a></li> -->
                <!-- <li><a href="https://cancercloudai.org/" target="_blank">CancerCloud AI</a></li> -->
                <!-- <li><a href="mailto:galoaa.b@northeastern.edu">Email Me</a></li> -->
            </ul>
        </div>
    </section>
    
    <footer>
        &copy; 2026 Bishoy M. Galoaa • Boston, MA
    </footer>
</main>

<script>
    // Function to toggle section collapse
    function toggleSection(section) {
        section.classList.toggle('collapsed');
    }
    
    // Set up the Professor dropdown with click functionality
    document.addEventListener('DOMContentLoaded', function() {
        // Get the dropdown element
        const professorDropdown = document.getElementById('professor-dropdown');
        const professorDropdownContent = professorDropdown.querySelector('.dropdown-content');
        
        // Add click event to the dropdown
        professorDropdown.addEventListener('click', function(event) {
            // Stop event from bubbling up to parent elements
            event.stopPropagation();
            
            // Toggle active class on dropdown content
            professorDropdownContent.classList.toggle('active');
        });
        
        // Make sure clicking links in the dropdown doesn't close sections
        professorDropdownContent.addEventListener('click', function(event) {
            // Stop propagation to prevent section toggle
            event.stopPropagation();
        });
        
        // Close dropdown when clicking elsewhere on the page
        document.addEventListener('click', function() {
            professorDropdownContent.classList.remove('active');
        });
    });
</script>
</body>
</html>